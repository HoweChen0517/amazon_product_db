{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/howechen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from stemming.porter2 import stem\n",
    "import networkx\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import Image\n",
    "import community as community_louvain\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "#pyo.init_notebook_mode()\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current woring directory: /Users/howechen/Project/ntu_sd6103_individual_assignment/amazon_product_db\n"
     ]
    }
   ],
   "source": [
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "print('current woring directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../ignore/data/'\n",
    "data_path = os.path.join(raw_data_path, 'amazon-meta.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open (data_path, 'r', encoding='utf-8', errors= 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集描述\n",
    "数据是 2006 年夏天通过抓取亚马逊网站收集的。数据集提供了 548,552 种不同产品的产品元数据和评论元数据信息。数据集中的每个产品都有以下信息：\n",
    "\n",
    "- 标题\n",
    "- 销售排名\n",
    "- 类似产品列表（与当前产品共同购买的产品）\n",
    "- 详细的产品分类\n",
    "- 产品评论：时间、客户、评分、投票数、认为评论有用的人数\n",
    "\n",
    "数据格式为:\n",
    "\n",
    "- ID： 产品编号（编号 0、......、548551）\n",
    "- ASIN：亚马逊标准识别码： 亚马逊标准识别码是亚马逊网站分配的用于产品识别的 10 个字符的字母数字唯一标识符。\n",
    "- 标题： 产品名称/标题\n",
    "- 组： 产品组可以是图书、DVD、视频或音乐\n",
    "- 销售排名：亚马逊销售排名代表产品与其主要类别中的其他产品相比的销售情况。排名越低，说明产品的销售情况越好。\n",
    "- 类似： 共同购买产品的 ASIN，例如购买 X 的人也会购买 Y\n",
    "- 类别： 产品所属类别在产品类别层次结构中的位置（用 | 分隔，类别 ID 在 [...] 中）\n",
    "- 评论： 产品评论信息，如评论总数、平均评分和单个客户评论信息，包括时间、用户 ID、评分、评论总票数、有用性总票数（表示有多少人认为该评论有用）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a nested product dictionary that will hold cleaned up amazon product data. \n",
    "amazonProducts= {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进入网络分析之前，需要进行一些预处理来读取文件，并将 ASIN 作为关键字，将其他数据作为与 ASIN 相关的元数据。\n",
    "\n",
    "- ID、ASIN、标题、销售排名、评论总数和平均评分与上述相同。\n",
    "- 与 ASIN 相关的所有类别都会被串联起来，然后进行文本预处理：小写、词干、去除数字/标点符号、去除停止词、只保留唯一词。\n",
    "- 类似 \"字段中的共同购买的 ASIN 将被过滤，只保留与之相关的元数据的 ASIN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the Amazon file and fill the amazonProducts nested dictionary\n",
    "(Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating, DegreeCentrality, ClusteringCoeff) = (\"\", \"\", \"\", \"\", \"\", \"\", 0, 0, 0.0, 0, 0.0)\n",
    "\n",
    "counter = 0\n",
    "for line in df:\n",
    "    line = line.strip()\n",
    "    if(line.startswith(\"Id\")): # a product block started\n",
    "        Id = line[3:].strip()\n",
    "    elif(line.startswith(\"ASIN\")):\n",
    "        ASIN = line[5:].strip()\n",
    "    elif(line.startswith(\"title\")):\n",
    "        Title = line[6:].strip()\n",
    "        Title = ' '.join(Title.split())\n",
    "    elif(line.startswith(\"group\")):\n",
    "        Group = line[6:].strip()\n",
    "    elif(line.startswith(\"salesrank\")):\n",
    "        SalesRank = line[10:].strip()\n",
    "    elif(line.startswith(\"similar\")):\n",
    "        ls = line.split()\n",
    "        Copurchased = ' '.join([c for c in ls[2:]])\n",
    "    elif(line.startswith(\"categories\")):\n",
    "        ls = line.split()\n",
    "        # print(ls)\n",
    "        Categories = ' '.join((df.readline()).lower() for i in range(int(ls[1].strip())))\n",
    "        # print(Categories)\n",
    "        Categories = re.compile('[%s]' % re.escape(string.digits+string.punctuation)).sub(' ',Categories)\n",
    "        # print(Categories)\n",
    "        Categories = ' '.join(set(Categories.split())-set(stopwords.words(\"english\")))\n",
    "        # print(Categories)\n",
    "        Categories = ' '.join(stem(word) for word in Categories.split())\n",
    "        # print(Categories)\n",
    "    elif(line.startswith(\"reviews\")):\n",
    "        ls = line.split()\n",
    "        # print(ls)\n",
    "        TotalReviews = ls[2].strip()\n",
    "        AvgRating = ls[7].strip() # a product block ended\n",
    "    elif (line==\"\"): # write out fields to amazonProducts dictionary\n",
    "        try:\n",
    "            MetaData = {}\n",
    "            if (ASIN != \"\"):\n",
    "                amazonProducts[ASIN] = MetaData\n",
    "            MetaData['Id'] = Id\n",
    "            MetaData['Title'] = Title\n",
    "            MetaData['Categories'] = ' '.join(set(Categories.split()))\n",
    "            MetaData['Group'] = Group\n",
    "            MetaData['Copurchased'] = Copurchased\n",
    "            MetaData['SalesRank'] = int(SalesRank)\n",
    "            MetaData['TotalReviews'] = int(TotalReviews)\n",
    "            MetaData['AvgRating'] = float(AvgRating)\n",
    "            MetaData['DegreeCentrality'] = DegreeCentrality\n",
    "            MetaData['ClusteringCoeff'] = ClusteringCoeff\n",
    "        except NameError:\n",
    "            continue\n",
    "        (Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating, DegreeCentrality, ClusteringCoeff) = (\"\", \"\", \"\", \"\", \"\", \"\", 0, 0, 0.0, 0, 0.0)\n",
    "        counter += 1\n",
    "    # if counter == 100:\n",
    "    #     break\n",
    "df.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该平台的目标是提供最大量的各种产品，同时让顾客在购买后对产品进行评论。然而，该平台于 1994 年作为一家在线书店开始运营。因此，再加上需要减少网络中可能存在的节点数量，我们决定只关注图书类产品。为此，下一步将是过滤亚马逊产品字典，使其只包含 Group=Book 并将其写入 amazonBooks 字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create book specific dictionary exclusively for books\n",
    "amazonBooks = {}\n",
    "for asin,metadata in amazonProducts.items():\n",
    "    if (metadata['Group']=='Book'):\n",
    "        amazonBooks[asin]=amazonProducts[asin]\n",
    "        \n",
    "#remove any copurchased items from copurchase list. If we don't have metadata associated with it\n",
    "for asin, metadata in amazonBooks.items():\n",
    "    amazonBooks[asin]['Copurchased']= ' '.join([cp for cp in metadata['Copurchased'].split() if cp in amazonBooks.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用亚马逊图书字典中的共同购买数据创建共同购买图结构如下：\n",
    "\n",
    "- 节点：是 ASIN\n",
    "- 边：如果两个 ASIN 共同购买，则存在于两个节点之间\n",
    "- 边缘权重：基于类别相似性\n",
    "- 相似度：这是对共同购买的任意两个 ASIN 之间的度量，可以用连接节点类别之间的共同词数除以两个连接节点类别中的总词数来计算。相似度范围从 0（最不相似）到 1（最相似）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a product copurchase graph for analysis\n",
    "#the graph nodes are product ASINs, the graph edge exists if two products were copurchased, with edge weight being a measure of category similarity between ASINs\n",
    "copurchaseGraph = networkx.Graph()\n",
    "for asin, metadata in amazonBooks.items():\n",
    "    copurchaseGraph.add_node(asin)\n",
    "    for a in metadata ['Copurchased'].split():\n",
    "        copurchaseGraph.add_node(a.strip())\n",
    "        similarity= 0\n",
    "        n1= set((amazonBooks[asin]['Categories']).split())\n",
    "        n2= set((amazonBooks[a]['Categories']).split())\n",
    "        n1In2 = n1 & n2 #intersection: number of words that are common between categories of connected nodes\n",
    "        n1Un2 = n1 | n2 #union: total number of words in both categories of connected nodes\n",
    "        if (len(n1Un2)) > 0:\n",
    "            similarity = round (len(n1In2)/len(n1Un2), 2)\n",
    "        copurchaseGraph.add_edge(asin, a.strip(), weight = similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在亚马逊图书字典中添加每个 ASIN 节点的图相关度量：度中心性和聚类系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degree centrality and clustering coefficients of each node and add it to amazonBooks metadata.\n",
    "dc = networkx.degree(copurchaseGraph)\n",
    "for asin in networkx.nodes(copurchaseGraph):\n",
    "    metadata = amazonBooks[asin]\n",
    "    metadata['DegreeCentrality'] = int(dc[asin])\n",
    "    ego = networkx.ego_graph(copurchaseGraph, asin, radius = 1)\n",
    "    metadata['ClusteringCoeff'] = round(networkx.average_clustering(ego), 2)\n",
    "    amazonBooks[asin] = metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，将亚马逊图书数据写入 amazon-books.txt 文件，并将共购图数据写入 amazon-books-copurchase.edgelist 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write amazonBooks data to file\n",
    "df1 = open('/Users/howechen/Project/eCommerce_DA/amazon-books.txt', 'w', encoding = 'utf-8', errors = 'ignore')\n",
    "df1.write('Id\\t' + 'ASIN\\t' + 'Title\\t'+\n",
    "         'Categories\\t' + 'Group\\t' + 'Copurchased\\t'+\n",
    "         'SalesRank\\t' + 'TotalReviews\\t' + 'AvgRating\\t'+\n",
    "         'DegreeCentrality\\t' + 'ClusteringCoeff\\n')\n",
    "for asin, metadata in amazonBooks.items():\n",
    "    df1.write(metadata['Id'] + '\\t' + \n",
    "              asin + '\\t' +\n",
    "              metadata['Title'] + '\\t' +\n",
    "              metadata['Categories'] + '\\t' +\n",
    "              metadata['Group'] + '\\t' +\n",
    "              metadata['Copurchased'] +'\\t' + \n",
    "              str(metadata['SalesRank']) + '\\t' +\n",
    "              str(metadata['TotalReviews']) + '\\t' +\n",
    "              str(metadata['AvgRating']) + '\\t' +\n",
    "              str(metadata['DegreeCentrality']) + '\\t' +\n",
    "              str(metadata['ClusteringCoeff']) + '\\n')\n",
    "df1.close()\n",
    "\n",
    "# Write copurchaseGraph to file\n",
    "df1 = open('/Users/howechen/Project/eCommerce_DA/amazon-books-copurchase.edgelist', 'wb')\n",
    "networkx.write_weighted_edgelist(copurchaseGraph, df1)\n",
    "df1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= open('amazon-books-copurchase.edgelist')\n",
    "copurchaseGraph = nx.read_weighted_edgelist(df2)\n",
    "df2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_rank(net):\n",
    "    degree_sequence = sorted((d for n, d in net.degree()), reverse=True)\n",
    "    df = pd.DataFrame(degree_sequence, columns = ['Degree'])\n",
    "    fig = px.scatter(df, y = 'Degree')\n",
    "    fig.update_layout(xaxis_title=\"Rank\")\n",
    "    fig.update_layout({\n",
    "        'plot_bgcolor' : 'rgba(0, 0, 0, 0)',\n",
    "        'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    })\n",
    "    return fig\n",
    "degree_rank(copurchaseGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_hist(net, kind = None, group = False):\n",
    "    if kind == 'in':  degrees = net.in_degree()\n",
    "    elif kind == 'out':  degrees = net.out_degree()\n",
    "    else: degrees = net.degree()\n",
    "   \n",
    "    df = pd.DataFrame(degrees, columns = ['Node', 'Degree'])\n",
    "    nbins = None if group else len(degrees)\n",
    "    fig = px.histogram(df, x=\"Degree\", nbins = nbins )\n",
    "    fig.update_layout(yaxis_title=\"# of Nodes\", bargap=0.01)\n",
    "    fig.update_layout({\n",
    "        'plot_bgcolor' : 'rgba(0, 0, 0, 0)',\n",
    "        'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    })\n",
    "    return fig  \n",
    "\n",
    "degree_hist(copurchaseGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open (data_path, 'r', encoding='utf-8', errors= 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "Id:   15\n",
    "ASIN: 1559362022\n",
    "  title: Wake Up and Smell the Coffee\n",
    "  group: Book\n",
    "  salesrank: 518927\n",
    "  similar: 5  1559360968  1559361247  1559360828  1559361018  0743214552\n",
    "  categories: 3\n",
    "   |Books[283155]|Subjects[1000]|Literature & Fiction[17]|Drama[2159]|United States[2160]\n",
    "   |Books[283155]|Subjects[1000]|Arts & Photography[1]|Performing Arts[521000]|Theater[2154]|General[2218]\n",
    "   |Books[283155]|Subjects[1000]|Literature & Fiction[17]|Authors, A-Z[70021]|( B )[70023]|Bogosian, Eric[70116]\n",
    "  reviews: total: 8  downloaded: 8  avg rating: 4\n",
    "    2002-5-13  cutomer: A2IGOA66Y6O8TQ  rating: 5  votes:   3  helpful:   2\n",
    "    2002-6-17  cutomer: A2OIN4AUH84KNE  rating: 5  votes:   2  helpful:   1\n",
    "    2003-1-2  cutomer: A2HN382JNT1CIU  rating: 1  votes:   6  helpful:   1\n",
    "    2003-6-7  cutomer: A2FDJ79LDU4O18  rating: 4  votes:   1  helpful:   1\n",
    "    2003-6-27  cutomer: A39QMV9ZKRJXO5  rating: 4  votes:   1  helpful:   1\n",
    "    2004-2-17  cutomer:  AUUVMSTQ1TXDI  rating: 1  votes:   2  helpful:   0\n",
    "    2004-2-24  cutomer: A2C5K0QTLL9UAT  rating: 5  votes:   2  helpful:   2\n",
    "    2004-10-13  cutomer:  A5XYF0Z3UH4HB  rating: 5  votes:   1  helpful:   1\n",
    "    -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数1：提取category和category_id对应关系，并添加到category_l列表中\n",
    "def extract_category_relations(line, category_l):\n",
    "    parts = line.strip().split('|')[1:]  # 跳过第一个空字符串（因为每行以 | 开头）\n",
    "    for part in parts:\n",
    "        match = re.search(r'(.+?)\\[(\\d+)\\]', part.strip())\n",
    "        if match:\n",
    "            category_name = re.sub(r'[^a-z]', '', match.group(1).lower())  # 仅保留字母的小写格式\n",
    "            category_id = match.group(2)\n",
    "            category_l.append({'category': category_name, 'category_id': category_id})\n",
    "\n",
    "# 函数2：将分类序列按category_id提取为字符串格式\n",
    "def extract_category_sequences(category_str):\n",
    "    category_sequences = []\n",
    "    lines = category_str.strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        sequence = []\n",
    "        parts = line.strip().split('|')[1:]  # 跳过第一个空字符串（因为每行以 | 开头）\n",
    "        \n",
    "        for part in parts:\n",
    "            match = re.search(r'\\[(\\d+)\\]', part.strip())\n",
    "            if match:\n",
    "                category_id = match.group(1)\n",
    "                sequence.append(category_id)\n",
    "        \n",
    "        category_sequences.append(\"/\".join(sequence))  # 用\"/\"连接每个category_id\n",
    "\n",
    "    # 将所有分类序列用\";\"连接\n",
    "    return \";\".join(category_sequences)\n",
    "\n",
    "# 函数3：解析评论信息并添加到 review_l 列表中\n",
    "def extract_reviews(review_str, product_ASIN, review_l):\n",
    "    # 分割每行评论\n",
    "    lines = review_str.strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        # 使用正则表达式提取评论中的字段\n",
    "        match = re.search(\n",
    "            r'(\\d{4}-\\d{1,2}-\\d{1,2})\\s+cutomer:\\s+(\\w+)\\s+rating:\\s+(\\d+)\\s+votes:\\s+(\\d+)\\s+helpful:\\s+(\\d+)', \n",
    "            line.strip()\n",
    "        )\n",
    "        \n",
    "        if match:\n",
    "            date, customer_id, rating, votes, helpful = match.groups()\n",
    "            # 创建评论字典并添加到 review_l 列表中\n",
    "            review_l.append({\n",
    "                'product_ASIN': product_ASIN,\n",
    "                'date': date,\n",
    "                'customer_id': customer_id,\n",
    "                'rating': int(rating),\n",
    "                'votes': int(votes),\n",
    "                'helpful': int(helpful)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonProducts = {}\n",
    "\n",
    "category_l = []\n",
    "review_l = []\n",
    "\n",
    "(Id, ASIN, title, group, salesrank, similar_items_num, similar_items, Tags, category_sequence, total_reviews_number, avg_rating) = (\"\", \"\", \"\", \"\", 0, 0, \"\", \"\", \"\", 0, 0)\n",
    "\n",
    "category_id_pattern = re.compile(r'[\\d+]')\n",
    "customer_id_pattern = re.compile(r'cutomer:\\s(\\s+)')\n",
    "avg_rating_pattern = re.compile(r'avg rating:\\s(\\d+\\.\\d+)')\n",
    "total_reviews_number_pattern = re.compile(r'total:\\s(\\d+)')\n",
    "\n",
    "for line in df:\n",
    "    line = line.strip()\n",
    "    if line.startswith('Id'):\n",
    "        Id = line[3:].strip()  # save to product_dict\n",
    "    elif line.startswith('ASIN'):\n",
    "        ASIN = line[5:].strip()  # save to product_dict\n",
    "    elif line.startswith('title'):\n",
    "        title = line[6:].strip()  # save to product_dict\n",
    "    elif line.startswith('group'):\n",
    "        group = line[6:].strip()\n",
    "        group = group.lower()  # save to product_dict\n",
    "    elif line.startswith('salesrank'):\n",
    "        salesrank = int(line[10:].strip())  # save to product_dict\n",
    "    elif line.startswith('similar'):\n",
    "        similar_items_num = line[8:].strip()[0]    # similar_items are separated by space -> save to product_dict\n",
    "        if similar_items_num != '0':\n",
    "            similar_items = line[8:].strip()[2:]\n",
    "        else:\n",
    "            similar_items = ''\n",
    "    elif line.startswith('categories'):\n",
    "        ls = line.split()\n",
    "        cate_records = ' '.join((df.readline()).lower() for i in range(int(ls[1].strip())))\n",
    "        Tags = re.compile('[%s]' % re.escape(string.digits+string.punctuation)).sub(' ',cate_records)\n",
    "        Tags = ' '.join(set(Tags.split())-set(stopwords.words(\"english\")))\n",
    "        Tags = ' '.join(stem(word) for word in Tags.split())\n",
    "        extract_category_relations(cate_records, category_l)    # save to a temp list\n",
    "        category_sequence = extract_category_sequences(cate_records)    # save to product dict\n",
    "    elif line.startswith('reviews'):\n",
    "        if avg_rating_pattern.search(line) and total_reviews_number_pattern.search(line):\n",
    "            avg_rating = float(avg_rating_pattern.search(line).group(1))\n",
    "            total_reviews_number = int(total_reviews_number_pattern.search(line).group(1))\n",
    "            All_reviews = ' '.join((df.readline()).lower() for i in range(total_reviews_number))\n",
    "            extract_reviews(All_reviews, ASIN, review_l)\n",
    "        else:\n",
    "            continue\n",
    "    elif line == '':\n",
    "        try:\n",
    "            MetaData = {}\n",
    "            if (ASIN != \"\"):\n",
    "                amazonProducts[ASIN] = MetaData\n",
    "            MetaData['Id'] = Id\n",
    "            MetaData['Title'] = title\n",
    "            MetaData['Group'] = group\n",
    "            MetaData['SalesRank'] = salesrank\n",
    "            MetaData['SimilarItemsNum'] = similar_items_num\n",
    "            MetaData['SimilarItems'] = similar_items\n",
    "            MetaData['CategorySequence'] = category_sequence\n",
    "            MetaData['Tags'] = Tags\n",
    "            MetaData['TotalReviewsNumber'] = total_reviews_number\n",
    "            MetaData['AvgRating'] = avg_rating\n",
    "        except NameError:\n",
    "            continue\n",
    "        (Id, ASIN, title, group, salesrank, similar_items_num, similar_items, Tags, category_sequence, total_reviews_number, avg_rating) = (\"\", \"\", \"\", \"\", 0, 0, \"\", \"\", \"\", 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540607, 12865906, 4081348)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amazonProducts.keys()), len(category_l), len(review_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540607, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonProducts_df = pd.DataFrame.from_dict(amazonProducts, orient='index')\n",
    "amazonProducts_df.index.name = 'ASIN'\n",
    "amazonProducts_df.reset_index(inplace=True)\n",
    "amazonProducts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Group</th>\n",
       "      <th>SalesRank</th>\n",
       "      <th>SimilarItemsNum</th>\n",
       "      <th>SimilarItems</th>\n",
       "      <th>CategorySequence</th>\n",
       "      <th>Tags</th>\n",
       "      <th>TotalReviewsNumber</th>\n",
       "      <th>AvgRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0771044445</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0827229534</td>\n",
       "      <td>1</td>\n",
       "      <td>Patterns of Preaching: A Sermon Sampler</td>\n",
       "      <td>book</td>\n",
       "      <td>396585</td>\n",
       "      <td>5</td>\n",
       "      <td>0804215715  156101074X  0687023955  068707423...</td>\n",
       "      <td>283155/1000/22/12290/12360/12368;283155/1000/2...</td>\n",
       "      <td>spiritu subject clergi preach religion christi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>2</td>\n",
       "      <td>Candlemas: Feast of Flames</td>\n",
       "      <td>book</td>\n",
       "      <td>168596</td>\n",
       "      <td>5</td>\n",
       "      <td>0738700827  1567184960  1567182836  073870052...</td>\n",
       "      <td>283155/1000/22/12472/12484;283155/1000/22/1247...</td>\n",
       "      <td>spiritu earth subject wicca witchcraft religio...</td>\n",
       "      <td>12</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0486287785</td>\n",
       "      <td>3</td>\n",
       "      <td>World War II Allied Fighter Planes Trading Cards</td>\n",
       "      <td>book</td>\n",
       "      <td>1270652</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>283155/1000/48/5126/5144</td>\n",
       "      <td>home subject garden hobbi craft general book</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0842328327</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Application Bible Commentary: 1 and 2 Tim...</td>\n",
       "      <td>book</td>\n",
       "      <td>631289</td>\n",
       "      <td>5</td>\n",
       "      <td>0842328130  0830818138  0842330313  084232861...</td>\n",
       "      <td>283155/1000/22/12290/172810/12155/12159;283155...</td>\n",
       "      <td>bibl christian testament guid text bibl religi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN Id                                              Title Group  \\\n",
       "0  0771044445  0                                                            \n",
       "1  0827229534  1            Patterns of Preaching: A Sermon Sampler  book   \n",
       "2  0738700797  2                         Candlemas: Feast of Flames  book   \n",
       "3  0486287785  3   World War II Allied Fighter Planes Trading Cards  book   \n",
       "4  0842328327  4  Life Application Bible Commentary: 1 and 2 Tim...  book   \n",
       "\n",
       "   SalesRank SimilarItemsNum  \\\n",
       "0          0               0   \n",
       "1     396585               5   \n",
       "2     168596               5   \n",
       "3    1270652               0   \n",
       "4     631289               5   \n",
       "\n",
       "                                        SimilarItems  \\\n",
       "0                                                      \n",
       "1   0804215715  156101074X  0687023955  068707423...   \n",
       "2   0738700827  1567184960  1567182836  073870052...   \n",
       "3                                                      \n",
       "4   0842328130  0830818138  0842330313  084232861...   \n",
       "\n",
       "                                    CategorySequence  \\\n",
       "0                                                      \n",
       "1  283155/1000/22/12290/12360/12368;283155/1000/2...   \n",
       "2  283155/1000/22/12472/12484;283155/1000/22/1247...   \n",
       "3                           283155/1000/48/5126/5144   \n",
       "4  283155/1000/22/12290/172810/12155/12159;283155...   \n",
       "\n",
       "                                                Tags  TotalReviewsNumber  \\\n",
       "0                                                                      0   \n",
       "1  spiritu subject clergi preach religion christi...                   0   \n",
       "2  spiritu earth subject wicca witchcraft religio...                  12   \n",
       "3       home subject garden hobbi craft general book                   0   \n",
       "4  bibl christian testament guid text bibl religi...                   0   \n",
       "\n",
       "   AvgRating  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        4.5  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonProducts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_path = '../ignore/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = os.path.join(save_data_path, 'amazon_products_total.csv')\n",
    "amazonProducts_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12865906, 2)\n",
      "(49683, 2)\n"
     ]
    }
   ],
   "source": [
    "category_df = pd.DataFrame(category_l)\n",
    "print(category_df.shape)\n",
    "category_df = category_df.drop_duplicates()\n",
    "print(category_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>CategoryID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>books</td>\n",
       "      <td>283155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subjects</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>religionspirituality</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christianity</td>\n",
       "      <td>12290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clergy</td>\n",
       "      <td>12360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category CategoryID\n",
       "0                 books     283155\n",
       "1              subjects       1000\n",
       "2  religionspirituality         22\n",
       "3          christianity      12290\n",
       "4                clergy      12360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df.rename(columns={'category': 'Category', 'category_id': 'CategoryId'}, inplace=True)\n",
    "category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25644, 49683)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df['Category'].nunique(), category_df['CategoryId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cate in category_df['Category'].unique():\n",
    "    temp_df = category_df[category_df['Category'] == cate]\n",
    "    if temp_df['CategoryId'].nunique() > 1:\n",
    "        # print(cate, temp_df['category_id'].unique())\n",
    "        dup_nums = len(temp_df['CategoryId'].unique())\n",
    "        for i in range(dup_nums):\n",
    "            category_df.loc[temp_df.index[i], 'Category'] = cate + '_' + str(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49683, 49683)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df['Category'].nunique(), category_df['CategoryId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>CategoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>books_1</td>\n",
       "      <td>283155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subjects_1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>religionspirituality_1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christianity_1</td>\n",
       "      <td>12290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clergy</td>\n",
       "      <td>12360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855926</th>\n",
       "      <td>varsidiane_2</td>\n",
       "      <td>450660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12856896</th>\n",
       "      <td>daytonlyman</td>\n",
       "      <td>456102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12857969</th>\n",
       "      <td>kermanken_2</td>\n",
       "      <td>431222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12860524</th>\n",
       "      <td>mathewscarole</td>\n",
       "      <td>435792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12863126</th>\n",
       "      <td>kellermarthe_2</td>\n",
       "      <td>430974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49683 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Category CategoryId\n",
       "0                        books_1     283155\n",
       "1                     subjects_1       1000\n",
       "2         religionspirituality_1         22\n",
       "3                 christianity_1      12290\n",
       "4                         clergy      12360\n",
       "...                          ...        ...\n",
       "12855926            varsidiane_2     450660\n",
       "12856896             daytonlyman     456102\n",
       "12857969             kermanken_2     431222\n",
       "12860524           mathewscarole     435792\n",
       "12863126          kellermarthe_2     430974\n",
       "\n",
       "[49683 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = category_df[['CategoryId', 'Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = category_df.sort_values(by='CategoryId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = os.path.join(save_data_path, 'amazon_category.csv')\n",
    "category_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Review Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4081348, 6)\n"
     ]
    }
   ],
   "source": [
    "review_df = pd.DataFrame(review_l)\n",
    "print(review_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>2001-12-16</td>\n",
       "      <td>a11nco6yte4btj</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>2002-1-7</td>\n",
       "      <td>a9cq3plrnir83</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>2002-1-24</td>\n",
       "      <td>a13sg9acz9o5im</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>2002-1-28</td>\n",
       "      <td>a1bdai6veymaza</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>2002-2-6</td>\n",
       "      <td>a2p6kawxj16234</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN        Date      CustomerId  Rating  Votes  Helpful\n",
       "0  0738700797  2001-12-16  a11nco6yte4btj       5      5        4\n",
       "1  0738700797    2002-1-7   a9cq3plrnir83       4      5        5\n",
       "2  0738700797   2002-1-24  a13sg9acz9o5im       5      8        8\n",
       "3  0738700797   2002-1-28  a1bdai6veymaza       5      4        4\n",
       "4  0738700797    2002-2-6  a2p6kawxj16234       4     16       16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.rename(columns={'product_ASIN': 'ASIN',\n",
    "                          'date':'Date',\n",
    "                          'customer_id':'CustomerId',\n",
    "                          'rating':'Rating',\n",
    "                          'votes':'Votes',\n",
    "                          'helpful':'Helpful'}, inplace=True)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['Date'] = pd.to_datetime(review_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[['ASIN', 'CustomerId', 'Date', 'Rating', 'Votes', 'Helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144037, 923593)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['ASIN'].nunique(), review_df['CustomerId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = os.path.join(save_data_path, 'amazon_reviews.csv')\n",
    "review_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Co-purchase Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "book            388472\n",
       "music           101612\n",
       "video            25505\n",
       "dvd              19215\n",
       "                  5783\n",
       "toy                  8\n",
       "software             5\n",
       "ce                   4\n",
       "video games          1\n",
       "baby product         1\n",
       "sports               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonProducts_df['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonBooks = {}\n",
    "for asin,metadata in amazonProducts.items():\n",
    "    if (metadata['Group']=='book'):\n",
    "        amazonBooks[asin]=amazonProducts[asin]\n",
    "\n",
    "amazonMusic = {}\n",
    "for asin,metadata in amazonProducts.items():\n",
    "    if (metadata['Group']=='music'):\n",
    "        amazonMusic[asin]=amazonProducts[asin]\n",
    "\n",
    "amazonVideo = {}\n",
    "for asin,metadata in amazonProducts.items():\n",
    "    if (metadata['Group']=='video'):\n",
    "        amazonVideo[asin]=amazonProducts[asin]\n",
    "\n",
    "for asin, metadata in amazonBooks.items():\n",
    "    amazonBooks[asin].update({'Copurchased': ' '.join([cp for cp in metadata['SimilarItems'].split() if cp in amazonBooks.keys()])})\n",
    "    # amazonBooks[asin]['Copurchased']= ' '.join([cp for cp in metadata['Copurchased'].split() if cp in amazonBooks.keys()])\n",
    "\n",
    "for asin, metadata in amazonMusic.items():\n",
    "    amazonMusic[asin].update({'Copurchased': ' '.join([cp for cp in metadata['SimilarItems'].split() if cp in amazonMusic.keys()])})\n",
    "    # amazonMusic[asin]['Copurchased']= ' '.join([cp for cp in metadata['Copurchased'].split() if cp in amazonMusic.keys()])\n",
    "\n",
    "for asin, metadata in amazonVideo.items():\n",
    "    amazonVideo[asin].update({'Copurchased': ' '.join([cp for cp in metadata['SimilarItems'].split() if cp in amazonVideo.keys()])})\n",
    "    # amazonVideo[asin]['Copurchased']= ' '.join([cp for cp in metadata['Copurchased'].split() if cp in amazonVideo.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a product copurchase graph for analysis\n",
    "#the graph nodes are product ASINs, the graph edge exists if two products were copurchased, with edge weight being a measure of category similarity between ASINs\n",
    "def create_copurchase_graph(targetCategory):\n",
    "    copurchaseGraph = networkx.Graph()\n",
    "    for asin, metadata in targetCategory.items():\n",
    "        copurchaseGraph.add_node(asin)\n",
    "        for a in metadata ['Copurchased'].split():\n",
    "            copurchaseGraph.add_node(a.strip())\n",
    "            similarity= 0\n",
    "            n1= set((targetCategory[asin]['Tags']).split())\n",
    "            n2= set((targetCategory[a]['Tags']).split())\n",
    "            n1In2 = n1 & n2 #intersection: number of words that are common between categories of connected nodes\n",
    "            n1Un2 = n1 | n2 #union: total number of words in both categories of connected nodes\n",
    "            if (len(n1Un2)) > 0:\n",
    "                similarity = round (len(n1In2)/len(n1Un2), 2)\n",
    "            copurchaseGraph.add_edge(asin, a.strip(), weight = similarity)\n",
    "            \n",
    "    return copurchaseGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_degree_centrality_clustering_coeff(targetCategory, copurchaseGraph):\n",
    "    dc = networkx.degree(copurchaseGraph)\n",
    "    for asin in networkx.nodes(copurchaseGraph):\n",
    "        metadata = targetCategory[asin]\n",
    "        metadata.update({'DegreeCentrality': int(dc[asin])})\n",
    "        ego = networkx.ego_graph(copurchaseGraph, asin, radius = 1)\n",
    "        metadata.update({'ClusteringCoeff': round(networkx.average_clustering(ego), 2)})\n",
    "        targetCategory[asin] = metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "copurchaseGraphBooks = create_copurchase_graph(amazonBooks)\n",
    "add_degree_centrality_clustering_coeff(amazonBooks, copurchaseGraphBooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write copurchaseGraph to file\n",
    "save_file_path = os.path.join(save_data_path, 'amazon-books-copurchase-edgelist.csv')\n",
    "edges = [(u, v, d['weight']) for u, v, d in copurchaseGraphBooks.edges(data=True)]\n",
    "edges_df = pd.DataFrame(edges, columns=['source', 'target', 'weight'])\n",
    "edges_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "copurchaseGraphMusic = create_copurchase_graph(amazonMusic)\n",
    "add_degree_centrality_clustering_coeff(amazonMusic, copurchaseGraphMusic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write copurchaseGraph to file\n",
    "save_file_path = os.path.join(save_data_path, 'amazon-music-copurchase-edgelist.csv')\n",
    "edges = [(u, v, d['weight']) for u, v, d in copurchaseGraphMusic.edges(data=True)]\n",
    "edges_df = pd.DataFrame(edges, columns=['source', 'target', 'weight'])\n",
    "edges_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "copurchaseGraphVideo = create_copurchase_graph(amazonVideo)\n",
    "add_degree_centrality_clustering_coeff(amazonVideo, copurchaseGraphVideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write copurchaseGraph to file\n",
    "save_file_path = os.path.join(save_data_path, 'amazon-video-copurchase-edgelist.csv')\n",
    "edges = [(u, v, d['weight']) for u, v, d in copurchaseGraphVideo.edges(data=True)]\n",
    "edges_df = pd.DataFrame(edges, columns=['source', 'target', 'weight'])\n",
    "edges_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388472, 14)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonBooks_df = pd.DataFrame.from_dict(amazonBooks, orient='index')\n",
    "amazonBooks_df.index.name = 'ASIN'\n",
    "amazonBooks_df.reset_index(inplace=True)\n",
    "amazonBooks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = os.path.join(save_data_path, 'amazon_books_with_sna.csv')\n",
    "amazonBooks_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101612, 14)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonMusic_df = pd.DataFrame.from_dict(amazonMusic, orient='index')\n",
    "amazonMusic_df.index.name = 'ASIN'\n",
    "amazonMusic_df.reset_index(inplace=True)\n",
    "amazonMusic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = os.path.join(save_data_path, 'amazon_music_with_sna.csv')\n",
    "amazonMusic_df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25505, 14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonVideo_df = pd.DataFrame.from_dict(amazonVideo, orient='index')\n",
    "amazonVideo_df.index.name = 'ASIN'\n",
    "amazonVideo_df.reset_index(inplace=True)\n",
    "amazonVideo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = os.path.join(save_data_path, 'amazon_video_with_sna.csv')\n",
    "amazonVideo_df.to_csv(save_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
